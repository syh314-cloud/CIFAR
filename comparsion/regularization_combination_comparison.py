"""
æ­£åˆ™åŒ–ç»„åˆå¯¹æ¯”å®éªŒ
å›ºå®šå‚æ•°ï¼š
- L2æ­£åˆ™åŒ–ç³»æ•°ï¼š5e-4
- Dropoutï¼šWarmup=10, p=(0.2, 0.3, 0.2)
- æ•°æ®å¢å¼ºï¼šCrop + Flip

æµ‹è¯•ç»„åˆï¼š
1. Baselineï¼ˆæ— æ­£åˆ™åŒ–ï¼‰
2. L2 only
3. Dropout only
4. Data Augmentation only
5. L2 + Dropout
6. L2 + Data Augmentation
7. Dropout + Data Augmentation
8. L2 + Dropout + Data Augmentationï¼ˆå…¨éƒ¨ç»„åˆï¼‰

ç›®æ ‡ï¼šæ‰¾åˆ°æœ€ä½³æ­£åˆ™åŒ–é…ç½®
"""

import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import cupy as np
    import numpy as np_cpu
except ImportError:
    import numpy as np
    np_cpu = np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import json
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ˜¾ç¤ºå‚æ•°
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

# ä¿®æ”¹å·¥ä½œç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
os.chdir(project_root)

from utils.data_loader import train_images, train_labels, val_images, val_labels, test_images, test_labels
from utils.data_augmentation import random_flip, random_crop
from model.mlp_4layer import MLP
from utils.loss import CrossEntropyLoss
from utils.classic_optimizers import Adam

class RegularizationCombinationExperiment:
    def __init__(self):
        self.SEED = 2023
        np.random.seed(self.SEED)
        
        # å›ºå®šè¶…å‚æ•°
        self.learning_rate = 7e-05
        self.batch_size = 64
        self.epochs = 100
        
        # å›ºå®šçš„æ­£åˆ™åŒ–å‚æ•°
        self.l2_lambda = 5e-4
        self.dropout_warmup = 10
        self.dropout_p = (0.2, 0.3, 0.2)  # (p1, p2, p3)
        
        # å®šä¹‰æ‰€æœ‰æµ‹è¯•é…ç½®
        self.configs = {
            'Baseline': {
                'name': 'Baseline',
                'use_l2': False,
                'use_dropout': False,
                'use_augmentation': False,
                'description': 'æ— æ­£åˆ™åŒ–'
            },
            'L2': {
                'name': 'L2 Only',
                'use_l2': True,
                'use_dropout': False,
                'use_augmentation': False,
                'description': f'L2æ­£åˆ™åŒ– (Î»={self.l2_lambda})'
            },
            'Dropout': {
                'name': 'Dropout Only',
                'use_l2': False,
                'use_dropout': True,
                'use_augmentation': False,
                'description': f'Dropout (Warmup={self.dropout_warmup}, p={self.dropout_p})'
            },
            'Augmentation': {
                'name': 'Data Aug Only',
                'use_l2': False,
                'use_dropout': False,
                'use_augmentation': True,
                'description': 'æ•°æ®å¢å¼º (Crop + Flip)'
            },
            'L2_Dropout': {
                'name': 'L2 + Dropout',
                'use_l2': True,
                'use_dropout': True,
                'use_augmentation': False,
                'description': 'L2 + Dropout'
            },
            'L2_Augmentation': {
                'name': 'L2 + Data Aug',
                'use_l2': True,
                'use_dropout': False,
                'use_augmentation': True,
                'description': 'L2 + æ•°æ®å¢å¼º'
            },
            'Dropout_Augmentation': {
                'name': 'Dropout + Data Aug',
                'use_l2': False,
                'use_dropout': True,
                'use_augmentation': True,
                'description': 'Dropout + æ•°æ®å¢å¼º'
            },
            'All': {
                'name': 'L2 + Dropout + Data Aug',
                'use_l2': True,
                'use_dropout': True,
                'use_augmentation': True,
                'description': 'å…¨éƒ¨æ­£åˆ™åŒ–'
            }
        }
        
        self.results = {}
    
    def _to_numpy(self, data):
        """å°†CuPyæ•°ç»„è½¬æ¢ä¸ºNumPyæ•°ç»„"""
        if hasattr(data, 'get'):
            return data.get()
        elif isinstance(data, list):
            return [self._to_numpy(item) for item in data]
        else:
            return data
    
    def _apply_augmentation(self, x):
        """åº”ç”¨Crop + Flipæ•°æ®å¢å¼º"""
        x = x.reshape(-1, 3, 32, 32)
        x = random_flip(x.copy(), prob=0.5)
        x = random_crop(x.copy(), crop_size=32, padding=4)
        return x.reshape(x.shape[0], -1)
    
    def train_single_model(self, config_name, config):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        print(f"\n{'='*80}")
        print(f"ğŸ”§ å¼€å§‹è®­ç»ƒ - {config['name']}")
        print(f"   é…ç½®: {config['description']}")
        print(f"{'='*80}")
        
        # é‡ç½®éšæœºç§å­
        np.random.seed(self.SEED)
        
        # åˆ›å»ºæ¨¡å‹
        model = MLP(train_images.shape[1], 1024, 512, 256, train_labels.shape[1])
        loss_fn = CrossEntropyLoss()
        optimizer = Adam(self.learning_rate, beta1=0.9, beta2=0.999)
        
        step_losses = []
        val_accuracies = []
        
        # é…ç½®Dropout
        if config['use_dropout']:
            # Dropoutä¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­æ ¹æ®epochè®¾ç½®
            pass
        else:
            # å…³é—­Dropout
            model.dropout1.p = 0.0
            model.dropout2.p = 0.0
            model.dropout3.p = 0.0
        
        # é…ç½®L2æ­£åˆ™åŒ–
        lambda_l2 = self.l2_lambda if config['use_l2'] else 0.0
        
        for epoch in range(self.epochs):
            # è®¾ç½®Dropout
            if config['use_dropout']:
                if epoch < self.dropout_warmup:
                    model.dropout1.p = 0.0
                    model.dropout2.p = 0.0
                    model.dropout3.p = 0.0
                else:
                    model.dropout1.p = self.dropout_p[0]
                    model.dropout2.p = self.dropout_p[1]
                    model.dropout3.p = self.dropout_p[2]
            
            np.random.seed(self.SEED + epoch)
            idx = np.random.permutation(train_images.shape[0])
            shuffled_images = train_images[idx]
            shuffled_labels = train_labels[idx]
            
            epoch_losses = []
            
            for i in range(0, shuffled_images.shape[0], self.batch_size):
                x = shuffled_images[i:i+self.batch_size]
                y = shuffled_labels[i:i+self.batch_size]
                
                # åº”ç”¨æ•°æ®å¢å¼º
                if config['use_augmentation']:
                    x = self._apply_augmentation(x)
                
                model.zero_grad()
                
                # æ ¹æ®æ˜¯å¦ä½¿ç”¨Dropoutå†³å®štrainingæ¨¡å¼
                training_mode = config['use_dropout']
                y_pred = model.forward(x, training=training_mode)
                
                loss = loss_fn.forward(y_pred, y, model, lambda_l2=lambda_l2)
                step_losses.append(loss)
                epoch_losses.append(loss)
                
                grad_output = loss_fn.backward()
                model.backward(grad_output)
                
                optimizer.step(model)
            
            # éªŒè¯å‡†ç¡®ç‡
            val_pred = model.forward(val_images, training=False)
            val_acc = np.mean(np.argmax(val_pred, axis=1) == np.argmax(val_labels, axis=1))
            val_accuracies.append(float(val_acc))
            
            if (epoch + 1) % 10 == 0:
                avg_loss = float(np.mean(np.array(epoch_losses)))
                print(f"Epoch {epoch+1}/{self.epochs} - Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        # æµ‹è¯•å‡†ç¡®ç‡
        test_pred = model.forward(test_images, training=False)
        test_acc = np.mean(np.argmax(test_pred, axis=1) == np.argmax(test_labels, axis=1))
        
        print(f"âœ… è®­ç»ƒå®Œæˆ - æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(val_accuracies):.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        
        return {
            'config_name': config_name,
            'display_name': config['name'],
            'description': config['description'],
            'use_l2': config['use_l2'],
            'use_dropout': config['use_dropout'],
            'use_augmentation': config['use_augmentation'],
            'step_losses': [float(x) for x in self._to_numpy(step_losses)],
            'val_accuracies': [float(x) for x in val_accuracies],
            'test_accuracy': float(test_acc),
            'best_val_accuracy': float(max(val_accuracies)),
            'steps_per_epoch': len(train_images) // self.batch_size
        }
    
    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("="*80)
        print("æ­£åˆ™åŒ–ç»„åˆå¯¹æ¯”å®éªŒ")
        print("="*80)
        print(f"å›ºå®šå‚æ•°:")
        print(f"  - Learning Rate: {self.learning_rate}")
        print(f"  - Batch Size: {self.batch_size}")
        print(f"  - Epochs: {self.epochs}")
        print(f"\næ­£åˆ™åŒ–å‚æ•°:")
        print(f"  - L2 Lambda: {self.l2_lambda}")
        print(f"  - Dropout Warmup: {self.dropout_warmup} epochs")
        print(f"  - Dropout p: {self.dropout_p}")
        print(f"  - Data Augmentation: Crop + Flip")
        print(f"\næµ‹è¯•é…ç½®æ•°é‡: {len(self.configs)}")
        print("="*80)
        
        # æŒ‰é¡ºåºè®­ç»ƒæ‰€æœ‰é…ç½®
        for config_name, config in self.configs.items():
            result = self.train_single_model(config_name, config)
            self.results[config_name] = result
        
        self.save_results()
        self.plot_results()
        self._print_summary()
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"regularization_combination_results_{timestamp}.json"
        
        save_data = {
            'experiment_config': {
                'learning_rate': self.learning_rate,
                'batch_size': self.batch_size,
                'epochs': self.epochs,
                'seed': self.SEED,
                'l2_lambda': self.l2_lambda,
                'dropout_warmup': self.dropout_warmup,
                'dropout_p': self.dropout_p
            },
            'results': self.results
        }
        
        with open(filename, 'w') as f:
            json.dump(save_data, f, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    def plot_results(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        fig = plt.figure(figsize=(20, 10))
        
        # å®šä¹‰é…ç½®é¡ºåºå’Œåˆ†ç»„
        config_order = ['Baseline', 'L2', 'Dropout', 'Augmentation', 
                       'L2_Dropout', 'L2_Augmentation', 'Dropout_Augmentation', 'All']
        
        colors = {
            'Baseline': '#95a5a6',
            'L2': '#3498db',
            'Dropout': '#e74c3c',
            'Augmentation': '#2ecc71',
            'L2_Dropout': '#9b59b6',
            'L2_Augmentation': '#f39c12',
            'Dropout_Augmentation': '#1abc9c',
            'All': '#e67e22'
        }
        
        # 1. éªŒè¯å‡†ç¡®ç‡æ›²çº¿
        ax1 = plt.subplot(2, 3, 1)
        for config_name in config_order:
            if config_name in self.results:
                result = self.results[config_name]
                ax1.plot(range(1, self.epochs + 1),
                        result['val_accuracies'],
                        label=result['display_name'],
                        color=colors[config_name],
                        linewidth=2, alpha=0.8,
                        linestyle='--' if config_name == 'Baseline' else '-')
        
        ax1.set_xlabel('Epoch', fontsize=11)
        ax1.set_ylabel('Validation Accuracy', fontsize=11)
        ax1.set_title('Validation Accuracy Curves', fontsize=12, fontweight='bold')
        ax1.legend(loc='best', framealpha=0.9, fontsize=8)
        ax1.grid(True, alpha=0.3, linestyle='--')
        
        # 2. éªŒè¯é›†å’Œæµ‹è¯•é›†å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆæŸ±çŠ¶å›¾ï¼‰
        ax2 = plt.subplot(2, 3, 2)
        
        display_names = [self.results[name]['display_name'] for name in config_order if name in self.results]
        val_accs = [self.results[name]['best_val_accuracy'] for name in config_order if name in self.results]
        test_accs = [self.results[name]['test_accuracy'] for name in config_order if name in self.results]
        
        x = self._to_numpy(np.arange(len(display_names)))
        width = 0.35
        
        bars1 = ax2.bar(x - width/2, val_accs, width,
                       label='Validation Accuracy',
                       color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=0.8)
        bars2 = ax2.bar(x + width/2, test_accs, width,
                       label='Test Accuracy',
                       color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=0.8)
        
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.4f}',
                        ha='center', va='bottom', fontsize=7)
        
        ax2.set_ylabel('Accuracy', fontsize=11)
        ax2.set_title('Val vs Test Accuracy', fontsize=12, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(display_names, rotation=30, ha='right', fontsize=8)
        ax2.legend(loc='best', framealpha=0.9)
        ax2.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax2.set_ylim([0, 1.0])
        
        # 3. ç›¸å¯¹Baselineçš„æå‡
        ax3 = plt.subplot(2, 3, 3)
        
        baseline_test = self.results['Baseline']['test_accuracy']
        improvements = []
        improvement_names = []
        improvement_colors = []
        
        for config_name in config_order:
            if config_name != 'Baseline' and config_name in self.results:
                improvement = self.results[config_name]['test_accuracy'] - baseline_test
                improvements.append(improvement)
                improvement_names.append(self.results[config_name]['display_name'])
                improvement_colors.append(colors[config_name])
        
        x_imp = self._to_numpy(np.arange(len(improvement_names)))
        bars = ax3.bar(x_imp, improvements, color=improvement_colors, alpha=0.8, edgecolor='black', linewidth=0.8)
        
        for bar in bars:
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:+.4f}',
                    ha='center', va='bottom' if height > 0 else 'top', fontsize=8)
        
        ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)
        ax3.set_ylabel('Test Accuracy Improvement', fontsize=11)
        ax3.set_title('Improvement over Baseline', fontsize=12, fontweight='bold')
        ax3.set_xticks(x_imp)
        ax3.set_xticklabels(improvement_names, rotation=30, ha='right', fontsize=8)
        ax3.grid(True, alpha=0.3, linestyle='--', axis='y')
        
        # 4. å•ç‹¬æ–¹æ³• vs ç»„åˆæ–¹æ³•å¯¹æ¯”
        ax4 = plt.subplot(2, 3, 4)
        
        single_methods = ['L2', 'Dropout', 'Augmentation']
        single_accs = [self.results[name]['test_accuracy'] for name in single_methods]
        
        combined_methods = ['L2_Dropout', 'L2_Augmentation', 'Dropout_Augmentation', 'All']
        combined_accs = [self.results[name]['test_accuracy'] for name in combined_methods]
        
        x_single = self._to_numpy(np.arange(len(single_methods)))
        x_combined = self._to_numpy(np.arange(len(combined_methods)))
        
        bars1 = ax4.bar(x_single, single_accs, 
                       color=[colors[name] for name in single_methods],
                       alpha=0.8, edgecolor='black', linewidth=0.8, label='Single')
        
        for i, bar in enumerate(bars1):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.4f}',
                    ha='center', va='bottom', fontsize=8)
        
        ax4.axhline(y=baseline_test, color='#95a5a6', linestyle='--', linewidth=2, label='Baseline')
        ax4.set_ylabel('Test Accuracy', fontsize=11)
        ax4.set_title('Single Regularization Methods', fontsize=12, fontweight='bold')
        ax4.set_xticks(x_single)
        ax4.set_xticklabels([self.results[name]['display_name'] for name in single_methods], 
                           rotation=20, ha='right', fontsize=9)
        ax4.legend(loc='best', framealpha=0.9)
        ax4.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax4.set_ylim([0, 1.0])
        
        # 5. ç»„åˆæ–¹æ³•å¯¹æ¯”
        ax5 = plt.subplot(2, 3, 5)
        
        bars2 = ax5.bar(x_combined, combined_accs,
                       color=[colors[name] for name in combined_methods],
                       alpha=0.8, edgecolor='black', linewidth=0.8)
        
        for bar in bars2:
            height = bar.get_height()
            ax5.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.4f}',
                    ha='center', va='bottom', fontsize=8)
        
        ax5.axhline(y=baseline_test, color='#95a5a6', linestyle='--', linewidth=2, label='Baseline')
        ax5.set_ylabel('Test Accuracy', fontsize=11)
        ax5.set_title('Combined Regularization Methods', fontsize=12, fontweight='bold')
        ax5.set_xticks(x_combined)
        ax5.set_xticklabels([self.results[name]['display_name'] for name in combined_methods],
                           rotation=20, ha='right', fontsize=8)
        ax5.legend(loc='best', framealpha=0.9)
        ax5.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax5.set_ylim([0, 1.0])
        
        # 6. æ’åå¯¹æ¯”ï¼ˆTopé…ç½®ï¼‰
        ax6 = plt.subplot(2, 3, 6)
        
        sorted_results = sorted(
            [(name, result) for name, result in self.results.items()],
            key=lambda x: x[1]['test_accuracy'],
            reverse=True
        )
        
        top_n = min(5, len(sorted_results))
        top_names = [result[1]['display_name'] for result in sorted_results[:top_n]]
        top_test = [result[1]['test_accuracy'] for result in sorted_results[:top_n]]
        top_val = [result[1]['best_val_accuracy'] for result in sorted_results[:top_n]]
        
        x_top = self._to_numpy(np.arange(top_n))
        width = 0.35
        
        bars1 = ax6.bar(x_top - width/2, top_val, width,
                       label='Validation Acc',
                       color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=0.8)
        bars2 = ax6.bar(x_top + width/2, top_test, width,
                       label='Test Acc',
                       color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=0.8)
        
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax6.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.4f}',
                        ha='center', va='bottom', fontsize=8)
        
        ax6.set_ylabel('Accuracy', fontsize=11)
        ax6.set_title(f'Top {top_n} Configurations', fontsize=12, fontweight='bold')
        ax6.set_xticks(x_top)
        ax6.set_xticklabels(top_names, rotation=20, ha='right', fontsize=9)
        ax6.legend(loc='best', framealpha=0.9)
        ax6.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax6.set_ylim([0, 1.0])
        
        plt.tight_layout()
        
        plot_filename = f"regularization_combination_plots_{timestamp}.png"
        plt.savefig(plot_filename, bbox_inches='tight')
        print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_filename}")
        plt.close()
    
    def _print_summary(self):
        """æ‰“å°å®éªŒæ€»ç»“"""
        print(f"\n{'='*80}")
        print("å®éªŒæ€»ç»“")
        print(f"{'='*80}")
        
        # æŒ‰æµ‹è¯•é›†å‡†ç¡®ç‡æ’åº
        sorted_results = sorted(
            self.results.items(),
            key=lambda x: x[1]['test_accuracy'],
            reverse=True
        )
        
        print("\nğŸ“Š æ‰€æœ‰é…ç½®ç»“æœï¼ˆæŒ‰æµ‹è¯•é›†å‡†ç¡®ç‡æ’åºï¼‰ï¼š")
        print("-"*80)
        for rank, (config_name, result) in enumerate(sorted_results, 1):
            print(f"{rank}. {result['display_name']:25s}: Val Acc={result['best_val_accuracy']:.4f}, Test Acc={result['test_accuracy']:.4f}")
        
        # æœ€ä½³é…ç½®
        best_config_name, best_result = sorted_results[0]
        baseline_test = self.results['Baseline']['test_accuracy']
        improvement = best_result['test_accuracy'] - baseline_test
        
        print(f"\nğŸ† æœ€ä½³é…ç½®:")
        print(f"   é…ç½®: {best_result['display_name']}")
        print(f"   æè¿°: {best_result['description']}")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {best_result['best_val_accuracy']:.4f}")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_result['test_accuracy']:.4f}")
        print(f"   ç›¸å¯¹Baselineæå‡: {improvement:+.4f} ({improvement*100:+.2f}%)")
        
        # åˆ†ææ³›åŒ–æ€§èƒ½
        gap = abs(best_result['best_val_accuracy'] - best_result['test_accuracy'])
        if gap > 0.02:
            print(f"   âš ï¸ éªŒè¯é›†å’Œæµ‹è¯•é›†å‡†ç¡®ç‡å·®è·: {gap:.4f}ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
        else:
            print(f"   âœ… éªŒè¯é›†å’Œæµ‹è¯•é›†å‡†ç¡®ç‡æ¥è¿‘ï¼Œæ³›åŒ–æ€§èƒ½è‰¯å¥½")
        
        # å•ç‹¬æ–¹æ³•å¯¹æ¯”
        print(f"\nğŸ“‹ å•ç‹¬æ­£åˆ™åŒ–æ–¹æ³•æ•ˆæœ:")
        for method in ['L2', 'Dropout', 'Augmentation']:
            result = self.results[method]
            improvement = result['test_accuracy'] - baseline_test
            print(f"   {result['display_name']:20s}: {result['test_accuracy']:.4f} ({improvement:+.4f})")
        
        # ç»„åˆæ–¹æ³•å¯¹æ¯”
        print(f"\nğŸ“‹ ç»„åˆæ­£åˆ™åŒ–æ–¹æ³•æ•ˆæœ:")
        for method in ['L2_Dropout', 'L2_Augmentation', 'Dropout_Augmentation', 'All']:
            result = self.results[method]
            improvement = result['test_accuracy'] - baseline_test
            print(f"   {result['display_name']:25s}: {result['test_accuracy']:.4f} ({improvement:+.4f})")
        
        print(f"{'='*80}\n")

def main():
    experiment = RegularizationCombinationExperiment()
    experiment.run_experiments()

if __name__ == "__main__":
    main()

