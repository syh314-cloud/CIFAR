"""
æ•°æ®å¢å¼ºå¯¹æ¯”å®éªŒ
æ‰¹é‡è®­ç»ƒæ¨¡å‹ï¼Œå¯¹æ¯”ä¸åŒæ•°æ®å¢å¼ºæ–¹æ³•çš„æ•ˆæœ
æµ‹è¯•æ–¹æ³•ï¼šFlipã€Cropã€Rotateã€Noiseã€æ— æ•°æ®å¢å¼ºï¼ˆBaselineï¼‰
ç”Ÿæˆè®­ç»ƒLossæ›²çº¿ã€éªŒè¯Accuracyæ›²çº¿å’Œæµ‹è¯•å‡†ç¡®ç‡æŸ±çŠ¶å›¾
"""

import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import cupy as np
    import numpy as np_cpu
except ImportError:
    import numpy as np
    np_cpu = np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®åç«¯ï¼Œé¿å…GUIé—®é¢˜
import matplotlib.pyplot as plt
import json
import os
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ˜¾ç¤ºå‚æ•°
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

# ä¿®æ”¹å·¥ä½œç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
os.chdir(project_root)

from utils.data_loader import train_images, train_labels, val_images, val_labels, test_images, test_labels
from utils.data_augmentation import random_flip, random_crop, random_rotate, random_noise
from model.mlp_4layer import MLP
from utils.loss import CrossEntropyLoss
from utils.classic_optimizers import Adam

class DataAugmentationExperiment:
    def __init__(self):
        self.SEED = 2023
        np.random.seed(self.SEED)
        
        # å›ºå®šè¶…å‚æ•°
        self.learning_rate = 7e-05
        self.batch_size = 64
        
        # è¦æµ‹è¯•çš„æ•°æ®å¢å¼ºæ–¹æ³• - åˆ†ä¸ºä¸¤ç»„å®éªŒ
        # ç¬¬ä¸€ç»„ï¼šå•ç‹¬æµ‹è¯•æ¯ç§æ–¹æ³•
        self.augmentation_configs_single = {
            'Flip': {
                'name': 'Flip',
                'function': lambda x: random_flip(x, prob=0.5)
            },
            'Crop': {
                'name': 'Crop',
                'function': lambda x: random_crop(x, crop_size=32, padding=4)
            },
            'Rotate': {
                'name': 'Rotate',
                'function': lambda x: random_rotate(x, max_angle=15)
            },
            'Noise': {
                'name': 'Noise',
                'function': lambda x: random_noise(x, std=0.02)
            }
        }
        
        # ç¬¬äºŒç»„ï¼šå åŠ æµ‹è¯•
        self.augmentation_configs_combined = {
            'Flip_Only': {
                'name': 'Flip',
                'function': lambda x: random_flip(x, prob=0.5)
            },
            'Flip_Crop': {
                'name': 'Flip + Crop',
                'function': lambda x: random_crop(random_flip(x, prob=0.5), crop_size=32, padding=4)
            },
            'Flip_Crop_Rotate': {
                'name': 'Flip + Crop + Rotate',
                'function': lambda x: random_rotate(random_crop(random_flip(x, prob=0.5), crop_size=32, padding=4), max_angle=15)
            },
            'Flip_Crop_Rotate_Noise': {
                'name': 'Flip + Crop + Rotate + Noise',
                'function': lambda x: random_noise(random_rotate(random_crop(random_flip(x, prob=0.5), crop_size=32, padding=4), max_angle=15), std=0.02)
            }
        }
        
        self.results_single = {}  # ç¬¬ä¸€ç»„ï¼šå•ç‹¬æµ‹è¯•ç»“æœ
        self.results_combined = {}  # ç¬¬äºŒç»„ï¼šå åŠ æµ‹è¯•ç»“æœ
        self.epochs = 100
    
    def _to_numpy(self, data):
        """å°†CuPyæ•°ç»„è½¬æ¢ä¸ºNumPyæ•°ç»„ç”¨äºmatplotlib"""
        if hasattr(data, 'get'):  # CuPyæ•°ç»„
            return data.get()
        elif isinstance(data, list):
            return [self._to_numpy(item) for item in data]
        else:
            return data

    def train_single_model(self, aug_name, aug_config):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        print(f"\nğŸ”§ å¼€å§‹è®­ç»ƒ - Augmentation: {aug_config['name']}")
        
        # é‡ç½®éšæœºç§å­ç¡®ä¿å…¬å¹³å¯¹æ¯”
        np.random.seed(self.SEED)
        
        # åˆ›å»ºæ¨¡å‹
        model = MLP(train_images.shape[1], 1024, 512, 256, train_labels.shape[1])
        loss_fn = CrossEntropyLoss()
        optimizer = Adam(self.learning_rate, beta1=0.9, beta2=0.999)
        
        step_losses = []  # è®°å½•æ¯ä¸ªstepçš„loss
        val_accuracies = []
        
        # å…³é—­æ‰€æœ‰Dropout
        model.dropout1.p = 0.0
        model.dropout2.p = 0.0
        model.dropout3.p = 0.0
        
        for epoch in range(self.epochs):
            np.random.seed(self.SEED + epoch)
            idx = np.random.permutation(train_images.shape[0])
            shuffled_images = train_images[idx]
            shuffled_labels = train_labels[idx]
            
            epoch_losses = []
            
            for i in range(0, shuffled_images.shape[0], self.batch_size):
                x = shuffled_images[i:i+self.batch_size]
                y = shuffled_labels[i:i+self.batch_size]
                
                # åº”ç”¨æ•°æ®å¢å¼º
                if aug_config['function'] is not None:
                    # é‡å¡‘ä¸º4Dæ•°ç»„ä»¥åº”ç”¨æ•°æ®å¢å¼º
                    x = x.reshape(-1, 3, 32, 32)
                    x = aug_config['function'](x.copy())
                    # é‡æ–°æ‰å¹³åŒ–
                    x = x.reshape(x.shape[0], -1)
                
                model.zero_grad()
                y_pred = model.forward(x, training=False)  # ä¸ä½¿ç”¨dropout
          
                loss = loss_fn.forward(y_pred, y, model, lambda_l2=0.0)  # ä¸ä½¿ç”¨L2æ­£åˆ™åŒ–
                step_losses.append(loss)  # è®°å½•æ¯ä¸ªstepçš„loss
                epoch_losses.append(loss)
                
                grad_output = loss_fn.backward()
                model.backward(grad_output)
                
                # æ›´æ–°å‚æ•°
                optimizer.step(model)
            
            # éªŒè¯å‡†ç¡®ç‡
            val_pred = model.forward(val_images, training=False)
            val_acc = np.mean(np.argmax(val_pred, axis=1) == np.argmax(val_labels, axis=1))
            val_accuracies.append(float(val_acc))
            
            if (epoch + 1) % 10 == 0:
                avg_loss = np.mean(epoch_losses)
                print(f"Epoch {epoch+1}/{self.epochs} - Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        # æµ‹è¯•å‡†ç¡®ç‡
        test_pred = model.forward(test_images, training=False)
        test_acc = np.mean(np.argmax(test_pred, axis=1) == np.argmax(test_labels, axis=1))
        
        # è®­ç»ƒé›†å‡†ç¡®ç‡
        train_pred = model.forward(train_images, training=False)
        train_acc = np.mean(np.argmax(train_pred, axis=1) == np.argmax(train_labels, axis=1))
        
        print(f"âœ… è®­ç»ƒå®Œæˆ - è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}, æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        
        return {
            'augmentation_method': aug_name,
            'augmentation_name': aug_config['name'],
            'step_losses': [float(x) for x in self._to_numpy(step_losses)],
            'val_accuracies': [float(x) for x in val_accuracies],
            'test_accuracy': float(test_acc),
            'train_accuracy': float(train_acc),
            'best_val_accuracy': float(max(val_accuracies)),
            'steps_per_epoch': len(train_images) // self.batch_size
        }
    
    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("="*80)
        print("æ•°æ®å¢å¼ºå¯¹æ¯”å®éªŒ")
        print("="*80)
        print(f"å›ºå®šå‚æ•°:")
        print(f"  - Learning Rate: {self.learning_rate}")
        print(f"  - Batch Size: {self.batch_size}")
        print(f"  - Epochs: {self.epochs}")
        print(f"  - L2 Regularization: 0.0 (å…³é—­)")
        print(f"  - Dropout: 0.0 (å…³é—­)")
        print("="*80)
        
        # ç¬¬ä¸€ç»„ï¼šå•ç‹¬æµ‹è¯•æ¯ç§æ–¹æ³•
        print(f"\nç¬¬ä¸€ç»„å®éªŒï¼šå•ç‹¬æµ‹è¯•æ¯ç§æ•°æ®å¢å¼ºæ–¹æ³•")
        print(f"æµ‹è¯•æ–¹æ³•: {', '.join([cfg['name'] for cfg in self.augmentation_configs_single.values()])}")
        print("-"*80)
        
        for aug_name, aug_config in self.augmentation_configs_single.items():
            result = self.train_single_model(aug_name, aug_config)
            self.results_single[aug_name] = result
        
        # ç¬¬äºŒç»„ï¼šå åŠ æµ‹è¯•
        print(f"\nç¬¬äºŒç»„å®éªŒï¼šå åŠ æµ‹è¯•æ•°æ®å¢å¼ºæ–¹æ³•")
        print(f"æµ‹è¯•æ–¹æ³•: {', '.join([cfg['name'] for cfg in self.augmentation_configs_combined.values()])}")
        print("-"*80)
        
        for aug_name, aug_config in self.augmentation_configs_combined.items():
            result = self.train_single_model(aug_name, aug_config)
            self.results_combined[aug_name] = result
        
        self.save_results()
        self.plot_results()
        self._print_summary()
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœåˆ°JSONæ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"data_augmentation_comparison_results_{timestamp}.json"
        
        save_data = {
            'experiment_config': {
                'learning_rate': self.learning_rate,
                'batch_size': self.batch_size,
                'epochs': self.epochs,
                'seed': self.SEED,
                'l2_regularization': 0.0,
                'dropout': 0.0
            },
            'results_single': self.results_single,
            'results_combined': self.results_combined
        }
        
        with open(filename, 'w') as f:
            json.dump(save_data, f, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    def plot_results(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ
        colors_single = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']
        colors_combined = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']
        
        # ========== ç¬¬ä¸€ç»„å›¾è¡¨ï¼šå•ç‹¬æµ‹è¯•æ¯ç§æ–¹æ³• ==========
        fig1 = plt.figure(figsize=(18, 5))
        
        # 1.1 è®­ç»ƒLossæ›²çº¿ï¼ˆæ¯500æ­¥é‡‡æ ·ä¸€æ¬¡ï¼‰
        ax1 = plt.subplot(1, 3, 1)
        sample_interval = 500
        for idx, (aug_name, result) in enumerate(self.results_single.items()):
            step_losses_np = np.array(result['step_losses'])
            sampled_steps = range(0, len(step_losses_np), sample_interval)
            sampled_losses = step_losses_np[sampled_steps]
            
            ax1.plot(sampled_steps, sampled_losses, 
                    label=result['augmentation_name'],
                    color=colors_single[idx % len(colors_single)],
                    linewidth=2, alpha=0.8)
        
        ax1.set_xlabel('Training Steps (sampled every 500 steps)', fontsize=11)
        ax1.set_ylabel('Loss', fontsize=11)
        ax1.set_title('Training Loss - Single Methods', fontsize=12, fontweight='bold')
        ax1.legend(loc='best', framealpha=0.9)
        ax1.grid(True, alpha=0.3, linestyle='--')
        ax1.set_xlim(left=0)
        
        # 1.2 éªŒè¯å‡†ç¡®ç‡æ›²çº¿
        ax2 = plt.subplot(1, 3, 2)
        for idx, (aug_name, result) in enumerate(self.results_single.items()):
            ax2.plot(range(1, self.epochs + 1), 
                    result['val_accuracies'],
                    label=result['augmentation_name'],
                    color=colors_single[idx % len(colors_single)],
                    linewidth=2, alpha=0.8)
        
        ax2.set_xlabel('Epoch', fontsize=11)
        ax2.set_ylabel('Validation Accuracy', fontsize=11)
        ax2.set_title('Validation Accuracy - Single Methods', fontsize=12, fontweight='bold')
        ax2.legend(loc='best', framealpha=0.9)
        ax2.grid(True, alpha=0.3, linestyle='--')
        
        # 1.3 è®­ç»ƒé›†å’Œæµ‹è¯•é›†å‡†ç¡®ç‡æŸ±çŠ¶å›¾
        ax3 = plt.subplot(1, 3, 3)
        
        aug_names = [result['augmentation_name'] for result in self.results_single.values()]
        train_accs = [result['train_accuracy'] for result in self.results_single.values()]
        test_accs = [result['test_accuracy'] for result in self.results_single.values()]
        
        x = self._to_numpy(np.arange(len(aug_names)))
        width = 0.35
        
        bars1 = ax3.bar(x - width/2, train_accs, width, 
                       label='Train Accuracy',
                       color='#3498db', alpha=0.8, edgecolor='black', linewidth=0.8)
        bars2 = ax3.bar(x + width/2, test_accs, width,
                       label='Test Accuracy',
                       color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=0.8)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax3.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.4f}',
                        ha='center', va='bottom', fontsize=8)
        
        ax3.set_xlabel('Data Augmentation Method', fontsize=11)
        ax3.set_ylabel('Accuracy', fontsize=11)
        ax3.set_title('Train vs Test Accuracy - Single Methods', fontsize=12, fontweight='bold')
        ax3.set_xticks(x)
        ax3.set_xticklabels(aug_names, rotation=15, ha='right')
        ax3.legend(loc='best', framealpha=0.9)
        ax3.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax3.set_ylim([0, 1.0])
        
        plt.tight_layout()
        
        plot_filename1 = f"data_augmentation_single_plots_{timestamp}.png"
        plt.savefig(plot_filename1, bbox_inches='tight')
        print(f"ğŸ“Š ç¬¬ä¸€ç»„å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_filename1}")
        plt.close()
        
        # ========== ç¬¬äºŒç»„å›¾è¡¨ï¼šå åŠ æµ‹è¯• ==========
        fig2 = plt.figure(figsize=(18, 5))
        
        # 2.1 è®­ç»ƒLossæ›²çº¿ï¼ˆæ¯500æ­¥é‡‡æ ·ä¸€æ¬¡ï¼‰
        ax4 = plt.subplot(1, 3, 1)
        sample_interval = 500
        for idx, (aug_name, result) in enumerate(self.results_combined.items()):
            step_losses_np = np.array(result['step_losses'])
            sampled_steps = range(0, len(step_losses_np), sample_interval)
            sampled_losses = step_losses_np[sampled_steps]
            
            ax4.plot(sampled_steps, sampled_losses, 
                    label=result['augmentation_name'],
                    color=colors_combined[idx % len(colors_combined)],
                    linewidth=2, alpha=0.8)
        
        ax4.set_xlabel('Training Steps (sampled every 500 steps)', fontsize=11)
        ax4.set_ylabel('Loss', fontsize=11)
        ax4.set_title('Training Loss - Combined Methods', fontsize=12, fontweight='bold')
        ax4.legend(loc='best', framealpha=0.9)
        ax4.grid(True, alpha=0.3, linestyle='--')
        ax4.set_xlim(left=0)
        
        # 2.2 éªŒè¯å‡†ç¡®ç‡æ›²çº¿
        ax5 = plt.subplot(1, 3, 2)
        for idx, (aug_name, result) in enumerate(self.results_combined.items()):
            ax5.plot(range(1, self.epochs + 1), 
                    result['val_accuracies'],
                    label=result['augmentation_name'],
                    color=colors_combined[idx % len(colors_combined)],
                    linewidth=2, alpha=0.8)
        
        ax5.set_xlabel('Epoch', fontsize=11)
        ax5.set_ylabel('Validation Accuracy', fontsize=11)
        ax5.set_title('Validation Accuracy - Combined Methods', fontsize=12, fontweight='bold')
        ax5.legend(loc='best', framealpha=0.9)
        ax5.grid(True, alpha=0.3, linestyle='--')
        
        # 2.3 éªŒè¯é›†å’Œæµ‹è¯•é›†å‡†ç¡®ç‡æŸ±çŠ¶å›¾
        ax6 = plt.subplot(1, 3, 3)
        
        aug_names_combined = [result['augmentation_name'] for result in self.results_combined.values()]
        val_accs_combined = [result['best_val_accuracy'] for result in self.results_combined.values()]
        test_accs_combined = [result['test_accuracy'] for result in self.results_combined.values()]
        
        x_combined = self._to_numpy(np.arange(len(aug_names_combined)))
        width = 0.35
        
        bars3 = ax6.bar(x_combined - width/2, val_accs_combined, width, 
                       label='Validation Accuracy',
                       color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=0.8)
        bars4 = ax6.bar(x_combined + width/2, test_accs_combined, width,
                       label='Test Accuracy',
                       color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=0.8)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars3, bars4]:
            for bar in bars:
                height = bar.get_height()
                ax6.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.4f}',
                        ha='center', va='bottom', fontsize=8)
        
        ax6.set_xlabel('Data Augmentation Method', fontsize=11)
        ax6.set_ylabel('Accuracy', fontsize=11)
        ax6.set_title('Val vs Test Accuracy - Combined Methods', fontsize=12, fontweight='bold')
        ax6.set_xticks(x_combined)
        ax6.set_xticklabels(aug_names_combined, rotation=15, ha='right')
        ax6.legend(loc='best', framealpha=0.9)
        ax6.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax6.set_ylim([0, 1.0])
        
        plt.tight_layout()
        
        plot_filename2 = f"data_augmentation_combined_plots_{timestamp}.png"
        plt.savefig(plot_filename2, bbox_inches='tight')
        print(f"ğŸ“Š ç¬¬äºŒç»„å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_filename2}")
        plt.close()
    
    def _print_summary(self):
        """æ‰“å°å®éªŒæ€»ç»“"""
        print(f"\n{'='*80}")
        print("å®éªŒæ€»ç»“")
        print(f"{'='*80}")
        
        print("\nç¬¬ä¸€ç»„ç»“æœ (å•ç‹¬æµ‹è¯•):")
        for aug_name, result in self.results_single.items():
            print(f"  {result['augmentation_name']:20s}: Train Acc={result['train_accuracy']:.4f}, Test Acc={result['test_accuracy']:.4f}")
        
        print("\nç¬¬äºŒç»„ç»“æœ (å åŠ æµ‹è¯•):")
        for aug_name, result in self.results_combined.items():
            print(f"  {result['augmentation_name']:25s}: Val Acc={result['best_val_accuracy']:.4f}, Test Acc={result['test_accuracy']:.4f}")
        
        # æ‰¾å‡ºå•ç‹¬æµ‹è¯•ä¸­æœ€ä½³çš„æ–¹æ³•
        best_single = max(self.results_single.items(), key=lambda x: x[1]['test_accuracy'])
        print(f"\nğŸ† ç¬¬ä¸€ç»„æœ€ä½³æ–¹æ³• (åŸºäºæµ‹è¯•é›†å‡†ç¡®ç‡): {best_single[1]['augmentation_name']}")
        print(f"   è®­ç»ƒå‡†ç¡®ç‡: {best_single[1]['train_accuracy']:.4f}")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_single[1]['test_accuracy']:.4f}")
        
        # æ‰¾å‡ºå åŠ æµ‹è¯•ä¸­æœ€ä½³çš„æ–¹æ³•
        best_combined = max(self.results_combined.items(), key=lambda x: x[1]['test_accuracy'])
        print(f"\nğŸ† ç¬¬äºŒç»„æœ€ä½³æ–¹æ³• (åŸºäºæµ‹è¯•é›†å‡†ç¡®ç‡): {best_combined[1]['augmentation_name']}")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {best_combined[1]['best_val_accuracy']:.4f}")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_combined[1]['test_accuracy']:.4f}")
        
        # åˆ†æå åŠ æ˜¯å¦å¸¦æ¥å¢ç›Š
        flip_only = self.results_combined['Flip_Only']['test_accuracy']
        flip_crop = self.results_combined['Flip_Crop']['test_accuracy']
        flip_crop_rotate = self.results_combined['Flip_Crop_Rotate']['test_accuracy']
        flip_crop_rotate_noise = self.results_combined['Flip_Crop_Rotate_Noise']['test_accuracy']
        
        print(f"\nğŸ“ˆ å åŠ å¢ç›Šåˆ†æ:")
        print(f"   Flip Only:                    {flip_only:.4f}")
        print(f"   Flip + Crop:                  {flip_crop:.4f} (å¢ç›Š: {flip_crop - flip_only:+.4f})")
        print(f"   Flip + Crop + Rotate:         {flip_crop_rotate:.4f} (å¢ç›Š: {flip_crop_rotate - flip_crop:+.4f})")
        print(f"   Flip + Crop + Rotate + Noise: {flip_crop_rotate_noise:.4f} (å¢ç›Š: {flip_crop_rotate_noise - flip_crop_rotate:+.4f})")
        
        print(f"{'='*80}\n")

def main():
    experiment = DataAugmentationExperiment()
    experiment.run_experiments()

if __name__ == "__main__":
    main()

