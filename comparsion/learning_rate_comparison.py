import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import cupy as np
    import numpy as np_cpu
except ImportError:
    import numpy as np
    np_cpu = np
import matplotlib.pyplot as plt
import matplotlib
import json
import os
from datetime import datetime

matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

from utils.data_loader import train_images, train_labels, val_images, val_labels, test_images, test_labels
from model.mlp_4layer import MLP
from utils.loss import CrossEntropyLoss, L2Scheduler
from utils.classic_optimizers import Adam
from utils.data_augmentation import augment_images

class LearningRateExperiment:
    def __init__(self):
        self.SEED = 2023
        np.random.seed(self.SEED)
        
        self.learning_rates = [0.00005, 0.0001, 0.0005, 0.001, 0.003, 0.01]
        
        self.results = {}
        
        self.batch_size = 64
        self.epochs = 100 
    
    def train_single_model(self, lr):
        np.random.seed(self.SEED)
        
        model = MLP(train_images.shape[1], 1024, 512, 256, train_labels.shape[1])
        loss_fn = CrossEntropyLoss()
        l2_scheduler = L2Scheduler(base_lambda=1e-4)
        optimizer = Adam(lr, beta1=0.9, beta2=0.999)
        
        lambda_l2 = l2_scheduler.base_lambda
        
        train_losses = []
        val_accuracies = []
        
        for epoch in range(self.epochs):
            if epoch < 20:
                model.dropout1.p = 0.0
                model.dropout2.p = 0.0
                model.dropout3.p = 0.0
            else:
                model.dropout1.p = 0.2
                model.dropout2.p = 0.3
                model.dropout3.p = 0.3
            
            np.random.seed(self.SEED + epoch)
            idx = np.random.permutation(train_images.shape[0])
            shuffled_images = train_images[idx]
            shuffled_labels = train_labels[idx]
            
            epoch_losses = []
            
            for i in range(0, shuffled_images.shape[0], self.batch_size):
                x = shuffled_images[i:i+self.batch_size]
                y = shuffled_labels[i:i+self.batch_size]
                
                x = x.reshape(-1, 3, 32, 32)
                x = augment_images(x, seed=self.SEED + epoch * 1000 + i)
                x = x.reshape(x.shape[0], -1)
                
                model.zero_grad()
                y_pred = model.forward(x, training=True)
          
                loss = loss_fn.forward(y_pred, y, model, lambda_l2=lambda_l2)
                epoch_losses.append(loss)
                
                grad_output = loss_fn.backward()
                model.backward(grad_output)
                
                for layer in model.layers:
                    if hasattr(layer, 'w'):
                        layer.dw += lambda_l2 * layer.w
                
                optimizer.step(model)
            
            val_pred = model.forward(val_images, training=False)
            val_acc = np.mean(np.argmax(val_pred, axis=1) == np.argmax(val_labels, axis=1))
            
            avg_loss = np.mean(epoch_losses)
            train_losses.append(avg_loss)
            val_accuracies.append(val_acc)
            
            if (epoch + 1) % 10 == 0:
                print(f"  Epoch {epoch+1:2d}/{self.epochs} - Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        test_pred = model.forward(test_images, training=False)
        test_acc = np.mean(np.argmax(test_pred, axis=1) == np.argmax(test_labels, axis=1))
        
        
        return {
            'train_losses': train_losses,
            'val_accuracies': val_accuracies,
            'test_accuracy': test_acc,
            'learning_rate': lr
        }
    
    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®žéªŒ"""
        print(f"\nðŸŽ¯ å¼€å§‹æ‰¹é‡è®­ç»ƒå®žéªŒ...")
        
        for i, lr in enumerate(self.learning_rates):
            print(f"\n{'='*60}")
            print(f"å®žéªŒè¿›åº¦: {i+1}/{len(self.learning_rates)}")
            
            result = self.train_single_model(lr)
            self.results[lr] = result
        
        print(f"\nðŸŽ‰ æ‰€æœ‰å®žéªŒå®Œæˆï¼")
        self.save_results()
        self.plot_results()
    
    def save_results(self):
        """ä¿å­˜å®žéªŒç»“æžœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"lr_comparison_results_{timestamp}.json"
        
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        results_to_save = {}
        for lr, result in self.results.items():
            train_losses = [float(x.get() if hasattr(x, 'get') else x) for x in result['train_losses']]
            val_accuracies = [float(x.get() if hasattr(x, 'get') else x) for x in result['val_accuracies']]
            test_accuracy = float(result['test_accuracy'].get() if hasattr(result['test_accuracy'], 'get') else result['test_accuracy'])
            results_to_save[str(lr)] = {
                'train_losses': train_losses,
                'val_accuracies': val_accuracies,
                'test_accuracy': test_accuracy,
                'learning_rate': float(result['learning_rate'])
            }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, indent=2, ensure_ascii=False)
        
        print(f"ðŸ“ ç»“æžœå·²ä¿å­˜åˆ°: {filename}")
    
    def plot_results(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨"""
        print(f"\nðŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('å­¦ä¹ çŽ‡å¯¹æ¯”å®žéªŒç»“æžœ', fontsize=16, fontweight='bold')
        
        # 1. è®­ç»ƒLossæ›²çº¿
        ax1 = axes[0, 0]
        for lr, result in self.results.items():
            ax1.plot(result['train_losses'], label=f'LR={lr}', linewidth=2)
        ax1.set_title('è®­ç»ƒé›† Loss æ›²çº¿', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. éªŒè¯Accuracyæ›²çº¿
        ax2 = axes[0, 1]
        for lr, result in self.results.items():
            ax2.plot(result['val_accuracies'], label=f'LR={lr}', linewidth=2)
        ax2.set_title('éªŒè¯é›† Accuracy æ›²çº¿', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. æµ‹è¯•å‡†ç¡®çŽ‡æŸ±çŠ¶å›¾
        ax3 = axes[1, 0]
        lrs = list(self.results.keys())
        test_accs = [self.results[lr]['test_accuracy'] for lr in lrs]
        
        bars = ax3.bar(range(len(lrs)), test_accs, 
                      color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD'])
        ax3.set_title('æµ‹è¯•é›†æœ€ç»ˆå‡†ç¡®çŽ‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax3.set_xlabel('å­¦ä¹ çŽ‡')
        ax3.set_ylabel('æµ‹è¯•å‡†ç¡®çŽ‡')
        ax3.set_xticks(range(len(lrs)))
        ax3.set_xticklabels([f'{lr}' for lr in lrs], rotation=45)
        ax3.grid(True, alpha=0.3, axis='y')
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, acc) in enumerate(zip(bars, test_accs)):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 4. æœ€ç»ˆæ”¶æ•›æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
        ax4 = axes[1, 1]
        ax4.axis('tight')
        ax4.axis('off')
        
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = []
        headers = ['å­¦ä¹ çŽ‡', 'æœ€ç»ˆLoss', 'æœ€ä½³Val Acc', 'æµ‹è¯•å‡†ç¡®çŽ‡']
        
        for lr in lrs:
            result = self.results[lr]
            final_loss = result['train_losses'][-1]
            best_val_acc = max(result['val_accuracies'])
            test_acc = result['test_accuracy']
            
            table_data.append([
                f'{lr}',
                f'{final_loss:.4f}',
                f'{best_val_acc:.4f}',
                f'{test_acc:.4f}'
            ])
        
        # åˆ›å»ºè¡¨æ ¼
        table = ax4.table(cellText=table_data, colLabels=headers,
                         cellLoc='center', loc='center',
                         colWidths=[0.2, 0.25, 0.25, 0.25])
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 2)
        
        # è®¾ç½®è¡¨æ ¼æ ·å¼
        for i in range(len(headers)):
            table[(0, i)].set_facecolor('#4ECDC4')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        ax4.set_title('æ€§èƒ½å¯¹æ¯”æ€»ç»“', fontsize=14, fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        plt.savefig(f'lr_comparison_plots_{timestamp}.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ðŸ“ˆ å›¾è¡¨å·²ä¿å­˜å¹¶æ˜¾ç¤º")
        
        # æ‰“å°æœ€ä½³ç»“æžœ
        best_lr = max(self.results.keys(), key=lambda lr: self.results[lr]['test_accuracy'])
        best_acc = self.results[best_lr]['test_accuracy']
        print(f"\nðŸ† æœ€ä½³å­¦ä¹ çŽ‡: {best_lr} (æµ‹è¯•å‡†ç¡®çŽ‡: {best_acc:.4f})")

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸŽ¯ å­¦ä¹ çŽ‡å¯¹æ¯”å®žéªŒ")
    print("=" * 60)
    
    # åˆ›å»ºå®žéªŒå¯¹è±¡
    experiment = LearningRateExperiment()
    
    # è¿è¡Œå®žéªŒ
    experiment.run_experiments()
    
    print("\nâœ… å®žéªŒå®Œæˆï¼")
    print("ðŸ“Š å·²ç”Ÿæˆ:")
    print("  - è®­ç»ƒLossæ›²çº¿")
    print("  - éªŒè¯Accuracyæ›²çº¿") 
    print("  - æµ‹è¯•å‡†ç¡®çŽ‡æŸ±çŠ¶å›¾")
    print("  - æ€§èƒ½å¯¹æ¯”è¡¨æ ¼")

if __name__ == "__main__":
    main()
