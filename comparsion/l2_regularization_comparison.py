"""
L2æ­£åˆ™åŒ–å¯¹æ¯”å®éªŒ
æ‰¹é‡è®­ç»ƒæ¨¡å‹ï¼Œå¯¹æ¯”ä¸åŒL2æ­£åˆ™åŒ–ç³»æ•°çš„æ•ˆæœ
ç”Ÿæˆè®­ç»ƒLossæ›²çº¿ã€éªŒè¯Accuracyæ›²çº¿å’Œæµ‹è¯•å‡†ç¡®ç‡æŸ±çŠ¶å›¾
"""

import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import cupy as np
    import numpy as np_cpu
except ImportError:
    import numpy as np
    np_cpu = np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®åç«¯ï¼Œé¿å…GUIé—®é¢˜
import matplotlib.pyplot as plt
import json
import os
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ˜¾ç¤ºå‚æ•°
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

# ä¿®æ”¹å·¥ä½œç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
os.chdir(project_root)

from utils.data_loader import train_images, train_labels, val_images, val_labels, test_images, test_labels
from model.mlp_4layer import MLP
from utils.loss import CrossEntropyLoss
from utils.classic_optimizers import Adam

class L2RegularizationExperiment:
    def __init__(self):
        self.SEED = 2023
        np.random.seed(self.SEED)
        
        # å›ºå®šè¶…å‚æ•°
        self.learning_rate = 7e-05
        self.batch_size = 64
        
        # è¦æµ‹è¯•çš„L2æ­£åˆ™åŒ–ç³»æ•°
        self.l2_lambdas = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]
        
        self.results = {}
        self.epochs = 100
    
    def _to_numpy(self, data):
        """å°†CuPyæ•°ç»„è½¬æ¢ä¸ºNumPyæ•°ç»„ç”¨äºmatplotlib"""
        if hasattr(data, 'get'):  # CuPyæ•°ç»„
            return data.get()
        elif isinstance(data, list):
            return [self._to_numpy(item) for item in data]
        else:
            return data

    def train_single_model(self, lambda_l2):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        print(f"\nğŸ”§ å¼€å§‹è®­ç»ƒ - L2 Lambda: {lambda_l2}")
        
        # é‡ç½®éšæœºç§å­ç¡®ä¿å…¬å¹³å¯¹æ¯”
        np.random.seed(self.SEED)
        
        # åˆ›å»ºæ¨¡å‹
        model = MLP(train_images.shape[1], 1024, 512, 256, train_labels.shape[1])
        loss_fn = CrossEntropyLoss()
        optimizer = Adam(self.learning_rate, beta1=0.9, beta2=0.999)
        
        step_losses = []  # è®°å½•æ¯ä¸ªstepçš„loss
        val_accuracies = []
        
        # å…³é—­æ‰€æœ‰Dropout
        model.dropout1.p = 0.0
        model.dropout2.p = 0.0
        model.dropout3.p = 0.0
        
        for epoch in range(self.epochs):
            np.random.seed(self.SEED + epoch)
            idx = np.random.permutation(train_images.shape[0])
            shuffled_images = train_images[idx]
            shuffled_labels = train_labels[idx]
            
            epoch_losses = []
            
            for i in range(0, shuffled_images.shape[0], self.batch_size):
                x = shuffled_images[i:i+self.batch_size]
                y = shuffled_labels[i:i+self.batch_size]
                
                model.zero_grad()
                y_pred = model.forward(x, training=False)  # ä¸ä½¿ç”¨dropout
          
                loss = loss_fn.forward(y_pred, y, model, lambda_l2=lambda_l2)
                step_losses.append(loss)  # è®°å½•æ¯ä¸ªstepçš„loss
                epoch_losses.append(loss)
                
                grad_output = loss_fn.backward()
                model.backward(grad_output)
                
                # æ·»åŠ L2æ­£åˆ™åŒ–æ¢¯åº¦
                for layer in model.layers:
                    if hasattr(layer, 'w'):
                        layer.dw += lambda_l2 * layer.w
                
                optimizer.step(model)
            
            val_pred = model.forward(val_images, training=False)
            val_acc = np.mean(np.argmax(val_pred, axis=1) == np.argmax(val_labels, axis=1))
            val_accuracies.append(val_acc)
            
            avg_loss = np.mean(np.array(epoch_losses))
            
            if (epoch + 1) % 10 == 0:
                print(f"  Epoch {epoch+1:2d}/{self.epochs} - Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        test_pred = model.forward(test_images, training=False)
        test_acc = np.mean(np.argmax(test_pred, axis=1) == np.argmax(test_labels, axis=1))
        
        # è·å–æœ€ä½³éªŒè¯å‡†ç¡®ç‡
        best_val_acc = np.max(np.array(val_accuracies))
        
        print(f"âœ… è®­ç»ƒå®Œæˆ - æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}, æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        
        return {
            'step_losses': step_losses,
            'val_accuracies': val_accuracies,
            'best_val_accuracy': best_val_acc,
            'test_accuracy': test_acc,
            'lambda_l2': lambda_l2
        }
    
    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print(f"\nğŸ¯ å¼€å§‹L2æ­£åˆ™åŒ–å¯¹æ¯”å®éªŒ...")
        print(f"ğŸ“Š å›ºå®šå­¦ä¹ ç‡: {self.learning_rate}")
        print(f"ğŸ“¦ å›ºå®šBatch Size: {self.batch_size}")
        print(f"ğŸ”§ æµ‹è¯•L2æ­£åˆ™åŒ–ç³»æ•°: {self.l2_lambdas}")
        print(f"âŒ å·²å…³é—­Dropoutå’Œæ•°æ®å¢å¼º")
        print("-" * 60)
        
        for i, lambda_l2 in enumerate(self.l2_lambdas):
            print(f"\n{'='*60}")
            print(f"å®éªŒè¿›åº¦: {i+1}/{len(self.l2_lambdas)}")
            
            result = self.train_single_model(lambda_l2)
            self.results[f'Î»={lambda_l2}'] = result
        
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
        self.save_results()
        self.plot_results()
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"l2_regularization_comparison_results_{timestamp}.json"
        
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        results_to_save = {}
        for l2_name, result in self.results.items():
            step_losses = [float(x.get() if hasattr(x, 'get') else x) for x in result['step_losses']]
            val_accuracies = [float(x.get() if hasattr(x, 'get') else x) for x in result['val_accuracies']]
            best_val_accuracy = float(result['best_val_accuracy'].get() if hasattr(result['best_val_accuracy'], 'get') else result['best_val_accuracy'])
            test_accuracy = float(result['test_accuracy'].get() if hasattr(result['test_accuracy'], 'get') else result['test_accuracy'])
            results_to_save[l2_name] = {
                'step_losses': step_losses,
                'val_accuracies': val_accuracies,
                'best_val_accuracy': best_val_accuracy,
                'test_accuracy': test_accuracy,
                'lambda_l2': result['lambda_l2'],
                'learning_rate': self.learning_rate,
                'batch_size': self.batch_size
            }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    def plot_results(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨ - å•ä¸ªæŸ±çŠ¶å›¾æ˜¾ç¤ºéªŒè¯é›†å’Œæµ‹è¯•é›†å‡†ç¡®ç‡"""
        print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨
        plt.close('all')  # å…³é—­ä¹‹å‰çš„å›¾è¡¨
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        fig.suptitle('L2 Regularization: Validation & Test Accuracy Comparison', 
                    fontsize=16, fontweight='bold', y=0.96)
        
        # å‡†å¤‡æ•°æ®
        l2_names = list(self.results.keys())
        val_accs = [self._to_numpy(self.results[name]['best_val_accuracy']) for name in l2_names]
        test_accs = [self._to_numpy(self.results[name]['test_accuracy']) for name in l2_names]
        
        # è®¾ç½®æŸ±çŠ¶å›¾å‚æ•°
        x = np.arange(len(l2_names))  # æ ‡ç­¾ä½ç½®
        width = 0.35  # æŸ±å­å®½åº¦
        
        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        bars1 = ax.bar(x - width/2, val_accs, width, label='Validation Accuracy',
                      color='#4ECDC4', alpha=0.8, edgecolor='black', linewidth=1.5)
        bars2 = ax.bar(x + width/2, test_accs, width, label='Test Accuracy',
                      color='#FF6B6B', alpha=0.8, edgecolor='black', linewidth=1.5)
        
        # æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜
        ax.set_xlabel('L2 Regularization Lambda (Î»)', fontsize=13, fontweight='bold')
        ax.set_ylabel('Accuracy', fontsize=13, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(l2_names, fontsize=11)
        ax.legend(fontsize=11, loc='lower right')
        ax.grid(True, alpha=0.3, axis='y', linestyle='--')
        ax.tick_params(axis='both', which='major', labelsize=11)
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                   f'{height:.4f}', ha='center', va='bottom', 
                   fontweight='bold', fontsize=9)
        
        for bar in bars2:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                   f'{height:.4f}', ha='center', va='bottom', 
                   fontweight='bold', fontsize=9)
        
        # è®¾ç½®yè½´èŒƒå›´ï¼Œç•™å‡ºç©ºé—´æ˜¾ç¤ºæ ‡ç­¾
        y_max = max(max(val_accs), max(test_accs))
        ax.set_ylim(0, y_max * 1.1)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout(rect=[0, 0.03, 1, 0.93])  # ä¸ºsuptitleç•™å‡ºç©ºé—´
        
        # ä¿å­˜å›¾è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f'l2_regularization_comparison_plots_{timestamp}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        
        print(f"ğŸ“ˆ å›¾è¡¨å·²ä¿å­˜åˆ°: {filename}")
        
        # å°è¯•æ˜¾ç¤ºå›¾è¡¨ï¼ˆå¦‚æœæœ‰GUIç¯å¢ƒï¼‰
        try:
            plt.show()
        except:
            print("ğŸ“± æ— GUIç¯å¢ƒï¼Œå›¾è¡¨å·²ä¿å­˜ä¸ºæ–‡ä»¶")
        
        # æ‰“å°æœ€ä½³ç»“æœ
        best_l2 = max(self.results.keys(), key=lambda name: self._to_numpy(self.results[name]['test_accuracy']))
        best_acc = self._to_numpy(self.results[best_l2]['test_accuracy'])
        print(f"\nğŸ† æœ€ä½³L2æ­£åˆ™åŒ–ç³»æ•°: {best_l2} (æµ‹è¯•å‡†ç¡®ç‡: {best_acc:.4f})")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ L2æ­£åˆ™åŒ–å¯¹æ¯”å®éªŒ")
    print("=" * 60)
    
    # åˆ›å»ºå®éªŒå¯¹è±¡
    experiment = L2RegularizationExperiment()
    
    # è¿è¡Œå®éªŒ
    experiment.run_experiments()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print("ğŸ“Š å·²ç”Ÿæˆ:")
    print("  - éªŒè¯é›†å’Œæµ‹è¯•é›†å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾")
    print("  - æ¯ä¸ªL2å‚æ•°æ˜¾ç¤ºä¸¤ä¸ªæŸ±ï¼šéªŒè¯é›†å‡†ç¡®ç‡å’Œæµ‹è¯•é›†å‡†ç¡®ç‡")

if __name__ == "__main__":
    main()

