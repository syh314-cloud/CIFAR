import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import cupy as np
    import numpy as np_cpu
except ImportError:
    import numpy as np
    np_cpu = np
import matplotlib.pyplot as plt
import matplotlib
import json
import os
from datetime import datetime

matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

from utils.data_loader import train_images, train_labels, val_images, val_labels, test_images, test_labels
from model.mlp_4layer import MLP
from utils.loss import CrossEntropyLoss, L2Scheduler
from utils.classic_optimizers import Adam
from utils.data_augmentation import augment_images

class LearningRateExperiment:
    def __init__(self):
        self.SEED = 2023
        np.random.seed(self.SEED)
        
        self.learning_rates = [0.00005, 0.0001, 0.0005, 0.001, 0.003, 0.01]
        
        self.results = {}
        
        self.batch_size = 64
        self.epochs = 100
    
    def _to_numpy(self, data):
        """Â∞ÜCuPyÊï∞ÁªÑËΩ¨Êç¢‰∏∫NumPyÊï∞ÁªÑÁî®‰∫ématplotlib"""
        if hasattr(data, 'get'):  # CuPyÊï∞ÁªÑ
            return data.get()
        elif isinstance(data, list):
            return [self._to_numpy(item) for item in data]
        else:
            return data 
    
    def train_single_model(self, lr):
        np.random.seed(self.SEED)
        
        model = MLP(train_images.shape[1], 1024, 512, 256, train_labels.shape[1])
        loss_fn = CrossEntropyLoss()
        l2_scheduler = L2Scheduler(base_lambda=1e-4)
        optimizer = Adam(lr, beta1=0.9, beta2=0.999)
        
        lambda_l2 = l2_scheduler.base_lambda
        
        train_losses = []
        val_accuracies = []
        
        for epoch in range(self.epochs):
            if epoch < 20:
                model.dropout1.p = 0.0
                model.dropout2.p = 0.0
                model.dropout3.p = 0.0
            else:
                model.dropout1.p = 0.2
                model.dropout2.p = 0.3
                model.dropout3.p = 0.3
            
            np.random.seed(self.SEED + epoch)
            idx = np.random.permutation(train_images.shape[0])
            shuffled_images = train_images[idx]
            shuffled_labels = train_labels[idx]
            
            epoch_losses = []
            
            for i in range(0, shuffled_images.shape[0], self.batch_size):
                x = shuffled_images[i:i+self.batch_size]
                y = shuffled_labels[i:i+self.batch_size]
                
                x = x.reshape(-1, 3, 32, 32)
                x = augment_images(x, seed=self.SEED + epoch * 1000 + i)
                x = x.reshape(x.shape[0], -1)
                
                model.zero_grad()
                y_pred = model.forward(x, training=True)
          
                loss = loss_fn.forward(y_pred, y, model, lambda_l2=lambda_l2)
                epoch_losses.append(loss)
                
                grad_output = loss_fn.backward()
                model.backward(grad_output)
                
                for layer in model.layers:
                    if hasattr(layer, 'w'):
                        layer.dw += lambda_l2 * layer.w
                
                optimizer.step(model)
            
            val_pred = model.forward(val_images, training=False)
            val_acc = np.mean(np.argmax(val_pred, axis=1) == np.argmax(val_labels, axis=1))
            
            avg_loss = np.mean(np.array(epoch_losses))
            train_losses.append(avg_loss)
            val_accuracies.append(val_acc)
            
            if (epoch + 1) % 10 == 0:
                print(f"  Epoch {epoch+1:2d}/{self.epochs} - Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        test_pred = model.forward(test_images, training=False)
        test_acc = np.mean(np.argmax(test_pred, axis=1) == np.argmax(test_labels, axis=1))
        
        
        return {
            'train_losses': train_losses,
            'val_accuracies': val_accuracies,
            'test_accuracy': test_acc,
            'learning_rate': lr
        }
    
    def run_experiments(self):
        """ËøêË°åÊâÄÊúâÂÆûÈ™å"""
        print(f"\nüéØ ÂºÄÂßãÊâπÈáèËÆ≠ÁªÉÂÆûÈ™å...")
        
        for i, lr in enumerate(self.learning_rates):
            print(f"\n{'='*60}")
            print(f"ÂÆûÈ™åËøõÂ∫¶: {i+1}/{len(self.learning_rates)}")
            
            result = self.train_single_model(lr)
            self.results[lr] = result
        
        print(f"\nüéâ ÊâÄÊúâÂÆûÈ™åÂÆåÊàêÔºÅ")
        self.save_results()
        self.plot_results()
    
    def save_results(self):
        """‰øùÂ≠òÂÆûÈ™åÁªìÊûú"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"lr_comparison_results_{timestamp}.json"
        
        # ËΩ¨Êç¢numpyÊï∞ÁªÑ‰∏∫ÂàóË°®‰ª•‰æøJSONÂ∫èÂàóÂåñ
        results_to_save = {}
        for lr, result in self.results.items():
            train_losses = [float(x.get() if hasattr(x, 'get') else x) for x in result['train_losses']]
            val_accuracies = [float(x.get() if hasattr(x, 'get') else x) for x in result['val_accuracies']]
            test_accuracy = float(result['test_accuracy'].get() if hasattr(result['test_accuracy'], 'get') else result['test_accuracy'])
            results_to_save[str(lr)] = {
                'train_losses': train_losses,
                'val_accuracies': val_accuracies,
                'test_accuracy': test_accuracy,
                'learning_rate': float(result['learning_rate'])
            }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, indent=2, ensure_ascii=False)
        
        print(f"üìÅ ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: {filename}")
    
    def plot_results(self):
        """ÁªòÂà∂ÂØπÊØîÂõæË°®"""
        print(f"\nüìä ÁîüÊàêÂèØËßÜÂåñÂõæË°®...")
        
        # ÂàõÂª∫ÂõæË°®
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Â≠¶‰π†ÁéáÂØπÊØîÂÆûÈ™åÁªìÊûú', fontsize=16, fontweight='bold')
        
        # 1. ËÆ≠ÁªÉLossÊõ≤Á∫ø
        ax1 = axes[0, 0]
        for lr, result in self.results.items():
            train_losses_np = self._to_numpy(result['train_losses'])
            ax1.plot(train_losses_np, label=f'LR={lr}', linewidth=2)
        ax1.set_title('ËÆ≠ÁªÉÈõÜ Loss Êõ≤Á∫ø', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. È™åËØÅAccuracyÊõ≤Á∫ø
        ax2 = axes[0, 1]
        for lr, result in self.results.items():
            val_accuracies_np = self._to_numpy(result['val_accuracies'])
            ax2.plot(val_accuracies_np, label=f'LR={lr}', linewidth=2)
        ax2.set_title('È™åËØÅÈõÜ Accuracy Êõ≤Á∫ø', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. ÊµãËØïÂáÜÁ°ÆÁéáÊü±Áä∂Âõæ
        ax3 = axes[1, 0]
        lrs = list(self.results.keys())
        test_accs = [self._to_numpy(self.results[lr]['test_accuracy']) for lr in lrs]
        
        bars = ax3.bar(range(len(lrs)), test_accs, 
                      color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD'])
        ax3.set_title('ÊµãËØïÈõÜÊúÄÁªàÂáÜÁ°ÆÁéáÂØπÊØî', fontsize=14, fontweight='bold')
        ax3.set_xlabel('Â≠¶‰π†Áéá')
        ax3.set_ylabel('ÊµãËØïÂáÜÁ°ÆÁéá')
        ax3.set_xticks(range(len(lrs)))
        ax3.set_xticklabels([f'{lr}' for lr in lrs], rotation=45)
        ax3.grid(True, alpha=0.3, axis='y')
        
        # Âú®Êü±Áä∂Âõæ‰∏äÊ∑ªÂä†Êï∞ÂÄºÊ†áÁ≠æ
        for i, (bar, acc) in enumerate(zip(bars, test_accs)):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 4. ÊúÄÁªàÊî∂ÊïõÊÄßËÉΩÂØπÊØîË°®Ê†º
        ax4 = axes[1, 1]
        ax4.axis('tight')
        ax4.axis('off')
        
        # ÂáÜÂ§áË°®Ê†ºÊï∞ÊçÆ
        table_data = []
        headers = ['Â≠¶‰π†Áéá', 'ÊúÄÁªàLoss', 'ÊúÄ‰Ω≥Val Acc', 'ÊµãËØïÂáÜÁ°ÆÁéá']
        
        for lr in lrs:
            result = self.results[lr]
            final_loss = self._to_numpy(result['train_losses'][-1])
            best_val_acc = max(self._to_numpy(result['val_accuracies']))
            test_acc = self._to_numpy(result['test_accuracy'])
            
            table_data.append([
                f'{lr}',
                f'{final_loss:.4f}',
                f'{best_val_acc:.4f}',
                f'{test_acc:.4f}'
            ])
        
        # ÂàõÂª∫Ë°®Ê†º
        table = ax4.table(cellText=table_data, colLabels=headers,
                         cellLoc='center', loc='center',
                         colWidths=[0.2, 0.25, 0.25, 0.25])
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 2)
        
        # ËÆæÁΩÆË°®Ê†ºÊ†∑Âºè
        for i in range(len(headers)):
            table[(0, i)].set_facecolor('#4ECDC4')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        ax4.set_title('ÊÄßËÉΩÂØπÊØîÊÄªÁªì', fontsize=14, fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        # ‰øùÂ≠òÂõæË°®
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        plt.savefig(f'lr_comparison_plots_{timestamp}.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"üìà ÂõæË°®Â∑≤‰øùÂ≠òÂπ∂ÊòæÁ§∫")
        
        # ÊâìÂç∞ÊúÄ‰Ω≥ÁªìÊûú
        best_lr = max(self.results.keys(), key=lambda lr: self._to_numpy(self.results[lr]['test_accuracy']))
        best_acc = self._to_numpy(self.results[best_lr]['test_accuracy'])
        print(f"\nüèÜ ÊúÄ‰Ω≥Â≠¶‰π†Áéá: {best_lr} (ÊµãËØïÂáÜÁ°ÆÁéá: {best_acc:.4f})")

def main():
    """‰∏ªÂáΩÊï∞"""
    print("üéØ Â≠¶‰π†ÁéáÂØπÊØîÂÆûÈ™å")
    print("=" * 60)
    
    # ÂàõÂª∫ÂÆûÈ™åÂØπË±°
    experiment = LearningRateExperiment()
    
    # ËøêË°åÂÆûÈ™å
    experiment.run_experiments()
    
    print("\n‚úÖ ÂÆûÈ™åÂÆåÊàêÔºÅ")
    print("üìä Â∑≤ÁîüÊàê:")
    print("  - ËÆ≠ÁªÉLossÊõ≤Á∫ø")
    print("  - È™åËØÅAccuracyÊõ≤Á∫ø") 
    print("  - ÊµãËØïÂáÜÁ°ÆÁéáÊü±Áä∂Âõæ")
    print("  - ÊÄßËÉΩÂØπÊØîË°®Ê†º")

if __name__ == "__main__":
    main()
