"""
MLPç½‘ç»œå®½åº¦å¯¹æ¯”å®éªŒ
æ‰¹é‡è®­ç»ƒæ¨¡å‹ï¼Œå¯¹æ¯”ä¸åŒéšè—å±‚ç¥ç»å…ƒæ•°é‡çš„æ•ˆæœ
ç”Ÿæˆè®­ç»ƒLossæ›²çº¿ã€éªŒè¯Accuracyæ›²çº¿å’Œæµ‹è¯•å‡†ç¡®ç‡æŸ±çŠ¶å›¾
"""

import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import cupy as np
    import numpy as np_cpu
except ImportError:
    import numpy as np
    np_cpu = np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®åç«¯ï¼Œé¿å…GUIé—®é¢˜
import matplotlib.pyplot as plt
import json
import os
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ˜¾ç¤ºå‚æ•°
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

from utils.data_loader import train_images, train_labels, val_images, val_labels, test_images, test_labels
from model.mlp_2layer import MLP
from utils.loss import CrossEntropyLoss, L2Scheduler
from utils.classic_optimizers import Adam
from utils.data_augmentation import augment_images

class NetworkWidthExperiment:
    def __init__(self):
        self.SEED = 2023
        np.random.seed(self.SEED)
        
        # å›ºå®šè¶…å‚æ•°
        self.learning_rate = 7e-05
        self.batch_size = 64
        
        # è¦æµ‹è¯•çš„éšè—å±‚ç¥ç»å…ƒæ•°é‡
        self.hidden_dims = [128, 256, 512, 1024, 2048]
        
        self.results = {}
        self.epochs = 100
    
    def _to_numpy(self, data):
        """å°†CuPyæ•°ç»„è½¬æ¢ä¸ºNumPyæ•°ç»„ç”¨äºmatplotlib"""
        if hasattr(data, 'get'):  # CuPyæ•°ç»„
            return data.get()
        elif isinstance(data, list):
            return [self._to_numpy(item) for item in data]
        else:
            return data

    def train_single_model(self, hidden_dim):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        print(f"\nğŸ”§ å¼€å§‹è®­ç»ƒ - Hidden Dim: {hidden_dim}")
        
        # é‡ç½®éšæœºç§å­ç¡®ä¿å…¬å¹³å¯¹æ¯”
        np.random.seed(self.SEED)
        
        # åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨2å±‚MLP
        model = MLP(train_images.shape[1], hidden_dim, train_labels.shape[1])
        loss_fn = CrossEntropyLoss()
        l2_scheduler = L2Scheduler(base_lambda=1e-4)
        optimizer = Adam(self.learning_rate, beta1=0.9, beta2=0.999)
        
        lambda_l2 = l2_scheduler.base_lambda
        
        step_losses = []  # è®°å½•æ¯ä¸ªstepçš„loss
        val_accuracies = []
        steps_per_epoch = len(range(0, train_images.shape[0], self.batch_size))
        
        for epoch in range(self.epochs):
            np.random.seed(self.SEED + epoch)
            idx = np.random.permutation(train_images.shape[0])
            shuffled_images = train_images[idx]
            shuffled_labels = train_labels[idx]
            
            epoch_losses = []
            
            for i in range(0, shuffled_images.shape[0], self.batch_size):
                x = shuffled_images[i:i+self.batch_size]
                y = shuffled_labels[i:i+self.batch_size]
                
                x = x.reshape(-1, 3, 32, 32)
                x = augment_images(x, seed=self.SEED + epoch * 1000 + i)
                x = x.reshape(x.shape[0], -1)
                
                model.zero_grad()
                y_pred = model.forward(x)
          
                loss = loss_fn.forward(y_pred, y, model, lambda_l2=lambda_l2)
                step_losses.append(loss)  # è®°å½•æ¯ä¸ªstepçš„loss
                epoch_losses.append(loss)
                
                grad_output = loss_fn.backward()
                model.backward(grad_output)
                
                for layer in model.layers:
                    if hasattr(layer, 'w'):
                        layer.dw += lambda_l2 * layer.w
                
                optimizer.step(model)
            
            val_pred = model.forward(val_images)
            val_acc = np.mean(np.argmax(val_pred, axis=1) == np.argmax(val_labels, axis=1))
            val_accuracies.append(val_acc)
            
            avg_loss = np.mean(np.array(epoch_losses))
            
            if (epoch + 1) % 10 == 0:
                print(f"  Epoch {epoch+1:2d}/{self.epochs} - Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        test_pred = model.forward(test_images)
        test_acc = np.mean(np.argmax(test_pred, axis=1) == np.argmax(test_labels, axis=1))
        
        print(f"âœ… è®­ç»ƒå®Œæˆ - æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        
        # è®¡ç®—æ¨¡å‹å‚æ•°é‡
        total_params = 0
        for layer in model.layers:
            if hasattr(layer, 'w'):
                total_params += layer.w.size + layer.b.size
        
        return {
            'step_losses': step_losses,  # æ¯ä¸ªstepçš„loss
            'val_accuracies': val_accuracies,
            'test_accuracy': test_acc,
            'hidden_dim': hidden_dim,
            'steps_per_epoch': steps_per_epoch,
            'total_params': int(total_params)
        }
    
    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print(f"\nğŸ¯ å¼€å§‹MLPç½‘ç»œå®½åº¦å¯¹æ¯”å®éªŒ...")
        print(f"ğŸ“Š å›ºå®šå­¦ä¹ ç‡: {self.learning_rate}")
        print(f"ğŸ“¦ å›ºå®šBatch Size: {self.batch_size}")
        print(f"ğŸ—ï¸  æµ‹è¯•éšè—å±‚ç»´åº¦: {self.hidden_dims}")
        print("-" * 60)
        
        for i, hidden_dim in enumerate(self.hidden_dims):
            print(f"\n{'='*60}")
            print(f"å®éªŒè¿›åº¦: {i+1}/{len(self.hidden_dims)}")
            
            result = self.train_single_model(hidden_dim)
            self.results[hidden_dim] = result
        
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
        self.save_results()
        self.plot_results()
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"network_width_comparison_results_{timestamp}.json"
        
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        results_to_save = {}
        for hidden_dim, result in self.results.items():
            step_losses = [float(x.get() if hasattr(x, 'get') else x) for x in result['step_losses']]
            val_accuracies = [float(x.get() if hasattr(x, 'get') else x) for x in result['val_accuracies']]
            test_accuracy = float(result['test_accuracy'].get() if hasattr(result['test_accuracy'], 'get') else result['test_accuracy'])
            results_to_save[str(hidden_dim)] = {
                'step_losses': step_losses,
                'val_accuracies': val_accuracies,
                'test_accuracy': test_accuracy,
                'hidden_dim': result['hidden_dim'],
                'steps_per_epoch': result['steps_per_epoch'],
                'total_params': result['total_params'],
                'learning_rate': self.learning_rate,
                'batch_size': self.batch_size
            }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    def plot_results(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨"""
        print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨
        plt.close('all')  # å…³é—­ä¹‹å‰çš„å›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Network Width Comparison Results (2-Layer MLP)', fontsize=18, fontweight='bold', y=0.98)
        
        # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
        
        # 1. è®­ç»ƒLossæ›²çº¿ (æŒ‰step)
        ax1 = axes[0, 0]
        for idx, (hidden_dim, result) in enumerate(self.results.items()):
            step_losses_np = self._to_numpy(result['step_losses'])
            steps = range(len(step_losses_np))
            # æ¯éš”ä¸€å®šæ­¥æ•°é‡‡æ ·ï¼Œé¿å…å›¾è¡¨è¿‡äºå¯†é›†
            sample_interval = 100
            sampled_steps = steps[::sample_interval]
            sampled_losses = step_losses_np[::sample_interval]
            ax1.plot(sampled_steps, sampled_losses, label=f'Hidden={hidden_dim}', 
                    color=colors[idx], linewidth=1.5, alpha=0.8)
        ax1.set_title('Training Loss Curves (Sampled every 100 steps)', fontsize=14, fontweight='bold', pad=15)
        ax1.set_xlabel('Training Steps', fontsize=12)
        ax1.set_ylabel('Loss', fontsize=12)
        ax1.set_xlim(left=0)
        ax1.legend(fontsize=10, loc='upper right')
        ax1.grid(True, alpha=0.3)
        ax1.tick_params(axis='both', which='major', labelsize=10)
        
        # 2. éªŒè¯Accuracyæ›²çº¿
        ax2 = axes[0, 1]
        for idx, (hidden_dim, result) in enumerate(self.results.items()):
            val_accuracies_np = self._to_numpy(result['val_accuracies'])
            ax2.plot(val_accuracies_np, label=f'Hidden={hidden_dim}', 
                    color=colors[idx], linewidth=2, marker='s', markersize=3)
        ax2.set_title('Validation Accuracy Curves', fontsize=14, fontweight='bold', pad=15)
        ax2.set_xlabel('Epoch', fontsize=12)
        ax2.set_ylabel('Accuracy', fontsize=12)
        ax2.legend(fontsize=10, loc='lower right')
        ax2.grid(True, alpha=0.3)
        ax2.tick_params(axis='both', which='major', labelsize=10)
        
        # 3. æµ‹è¯•å‡†ç¡®ç‡æŸ±çŠ¶å›¾
        ax3 = axes[1, 0]
        hidden_dims = list(self.results.keys())
        test_accs = [self._to_numpy(self.results[hd]['test_accuracy']) for hd in hidden_dims]
        
        bars = ax3.bar(range(len(hidden_dims)), test_accs, 
                      color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        ax3.set_title('Final Test Accuracy Comparison', fontsize=14, fontweight='bold', pad=15)
        ax3.set_xlabel('Hidden Layer Dimension', fontsize=12)
        ax3.set_ylabel('Test Accuracy', fontsize=12)
        ax3.set_xticks(range(len(hidden_dims)))
        ax3.set_xticklabels([f'{hd}' for hd in hidden_dims], fontsize=10)
        ax3.grid(True, alpha=0.3, axis='y')
        ax3.tick_params(axis='both', which='major', labelsize=10)
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, acc) in enumerate(zip(bars, test_accs)):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                    f'{acc:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        # 4. æœ€ç»ˆæ”¶æ•›æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
        ax4 = axes[1, 1]
        ax4.axis('tight')
        ax4.axis('off')
        
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = []
        headers = ['Hidden Dim', 'å‚æ•°é‡', 'æœ€ç»ˆLoss', 'æœ€ä½³Val Acc', 'æµ‹è¯•å‡†ç¡®ç‡']
        
        for hidden_dim in hidden_dims:
            result = self.results[hidden_dim]
            total_params = result['total_params']
            final_loss = self._to_numpy(result['step_losses'][-1])
            best_val_acc = max(self._to_numpy(result['val_accuracies']))
            test_acc = self._to_numpy(result['test_accuracy'])
            
            table_data.append([
                f'{hidden_dim}',
                f'{total_params:,}',
                f'{final_loss:.4f}',
                f'{best_val_acc:.4f}',
                f'{test_acc:.4f}'
            ])
        
        # åˆ›å»ºè¡¨æ ¼
        table = ax4.table(cellText=table_data, colLabels=headers,
                         cellLoc='center', loc='center',
                         colWidths=[0.15, 0.2, 0.2, 0.2, 0.2])
        table.auto_set_font_size(False)
        table.set_fontsize(9)
        table.scale(1, 2)
        
        # è®¾ç½®è¡¨æ ¼æ ·å¼
        for i in range(len(headers)):
            table[(0, i)].set_facecolor('#4ECDC4')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        ax4.set_title('Performance Summary', fontsize=14, fontweight='bold', pad=20)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        
        # ä¿å­˜å›¾è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f'network_width_comparison_plots_{timestamp}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        
        print(f"ğŸ“ˆ å›¾è¡¨å·²ä¿å­˜åˆ°: {filename}")
        
        # å°è¯•æ˜¾ç¤ºå›¾è¡¨ï¼ˆå¦‚æœæœ‰GUIç¯å¢ƒï¼‰
        try:
            plt.show()
        except:
            print("ğŸ“± æ— GUIç¯å¢ƒï¼Œå›¾è¡¨å·²ä¿å­˜ä¸ºæ–‡ä»¶")
        
        # æ‰“å°æœ€ä½³ç»“æœ
        best_hd = max(self.results.keys(), key=lambda hd: self._to_numpy(self.results[hd]['test_accuracy']))
        best_acc = self._to_numpy(self.results[best_hd]['test_accuracy'])
        print(f"\nğŸ† æœ€ä½³ç½‘ç»œå®½åº¦: {best_hd} (æµ‹è¯•å‡†ç¡®ç‡: {best_acc:.4f})")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ MLPç½‘ç»œå®½åº¦å¯¹æ¯”å®éªŒ")
    print("=" * 60)
    
    # åˆ›å»ºå®éªŒå¯¹è±¡
    experiment = NetworkWidthExperiment()
    
    # è¿è¡Œå®éªŒ
    experiment.run_experiments()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print("ğŸ“Š å·²ç”Ÿæˆ:")
    print("  - è®­ç»ƒLossæ›²çº¿ (æŒ‰æ­¥æ•°)")
    print("  - éªŒè¯Accuracyæ›²çº¿") 
    print("  - æµ‹è¯•å‡†ç¡®ç‡æŸ±çŠ¶å›¾")
    print("  - æ€§èƒ½å¯¹æ¯”è¡¨æ ¼ï¼ˆåŒ…å«å‚æ•°é‡ï¼‰")

if __name__ == "__main__":
    main()
