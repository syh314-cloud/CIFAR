#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹è¯„ä¼°è„šæœ¬ - æµ‹è¯•å·²è®­ç»ƒæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½
"""

import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.data_loader import test_images, test_labels
from model.mlp_4layer import MLP
from utils.loss import CrossEntropyLoss
from utils.optimizers import Momentum
from utils.metrics import (
    accuracy, top_k_accuracy, confusion_matrix, 
    classification_report, print_confusion_matrix, CIFAR10_CLASSES
)

def evaluate_test_set():
    """
    è¯„ä¼°æµ‹è¯•é›†æ€§èƒ½
    æ³¨æ„ï¼šéœ€è¦å…ˆè¿è¡Œtrain.pyè®­ç»ƒæ¨¡å‹ï¼Œè¿™é‡Œä¼šé‡æ–°åˆ›å»ºç›¸åŒçš„æ¨¡å‹ç»“æ„
    """
    print("ğŸ¯ æµ‹è¯•é›†è¯„ä¼°")
    print("="*50)
    
    # åˆ›å»ºä¸train.pyç›¸åŒçš„æ¨¡å‹ç»“æ„
    model = MLP(test_images.shape[1], 1024, 512, 256, 10)
    
    # æ³¨æ„ï¼šè¿™é‡Œåº”è¯¥åŠ è½½è®­ç»ƒå¥½çš„æƒé‡ï¼Œä½†ç”±äºæ²¡æœ‰ä¿å­˜åŠŸèƒ½ï¼Œ
    # å®é™…ä½¿ç”¨æ—¶éœ€è¦å…ˆè¿è¡Œtrain.pyæˆ–è€…æ·»åŠ æ¨¡å‹ä¿å­˜/åŠ è½½åŠŸèƒ½
    print("âš ï¸  æ³¨æ„ï¼šå½“å‰ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æƒé‡")
    print("   å®é™…ä½¿ç”¨æ—¶åº”è¯¥åŠ è½½train.pyè®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡")
    print()
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutï¼‰
    model.dropout1.p = 0.0
    model.dropout2.p = 0.0
    model.dropout3.p = 0.0
    
    # è·å–æµ‹è¯•é›†é¢„æµ‹
    print("ğŸ”® ç”Ÿæˆæµ‹è¯•é›†é¢„æµ‹...")
    test_pred = model.forward(test_images, training=False)
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    print("\nğŸ“Š æµ‹è¯•é›†æ€§èƒ½æŒ‡æ ‡:")
    print("-" * 40)
    
    # 1. å‡†ç¡®ç‡
    test_acc = accuracy(test_pred, test_labels)
    print(f"å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
    
    # 2. Top-5å‡†ç¡®ç‡
    top5_acc = top_k_accuracy(test_pred, test_labels, k=5)
    print(f"Top-5å‡†ç¡®ç‡: {top5_acc:.4f} ({top5_acc*100:.2f}%)")
    
    # 3. æŸå¤±
    loss_fn = CrossEntropyLoss()
    test_loss = loss_fn.forward(test_pred, test_labels)
    print(f"äº¤å‰ç†µæŸå¤±: {test_loss:.4f}")
    
    # 4. æ··æ·†çŸ©é˜µ
    print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ:")
    cm = confusion_matrix(test_pred, test_labels)
    print_confusion_matrix(cm, CIFAR10_CLASSES)
    
    # 5. è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print(f"\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    report = classification_report(test_pred, test_labels, CIFAR10_CLASSES)
    
    # 6. å„ç±»åˆ«å‡†ç¡®ç‡
    print(f"\nğŸ“ˆ å„ç±»åˆ«å‡†ç¡®ç‡:")
    print("-" * 30)
    pred_labels = np.argmax(test_pred, axis=1)
    true_labels = np.argmax(test_labels, axis=1)
    
    for i, class_name in enumerate(CIFAR10_CLASSES):
        class_mask = (true_labels == i)
        if np.sum(class_mask) > 0:
            class_acc = np.mean(pred_labels[class_mask] == true_labels[class_mask])
            print(f"{class_name:<12}: {class_acc:.4f} ({class_acc*100:.2f}%)")
    
    # 7. æ€»ç»“
    print(f"\nğŸ¯ æµ‹è¯•é›†è¯„ä¼°æ€»ç»“:")
    print("="*30)
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_images)}")
    print(f"æ€»ä½“å‡†ç¡®ç‡: {test_acc*100:.2f}%")
    print(f"Top-5å‡†ç¡®ç‡: {top5_acc*100:.2f}%")
    
    # æ€§èƒ½è¯„çº§
    if test_acc >= 0.6:
        grade = "ä¼˜ç§€ ğŸ†"
    elif test_acc >= 0.5:
        grade = "è‰¯å¥½ ğŸ‘"
    elif test_acc >= 0.4:
        grade = "ä¸€èˆ¬ ğŸ“ˆ"
    else:
        grade = "éœ€è¦æ”¹è¿› âš ï¸"
    
    print(f"æ€§èƒ½è¯„çº§: {grade}")
    
    return {
        'accuracy': test_acc,
        'top5_accuracy': top5_acc,
        'loss': test_loss,
        'confusion_matrix': cm,
        'predictions': test_pred
    }

if __name__ == "__main__":
    print("ğŸ§ª ç¥ç»ç½‘ç»œæµ‹è¯•é›†è¯„ä¼°")
    print(f"æµ‹è¯•é›†å½¢çŠ¶: {test_images.shape}")
    print(f"æ ‡ç­¾å½¢çŠ¶: {test_labels.shape}")
    print(f"ç±»åˆ«æ•°: {len(CIFAR10_CLASSES)}")
    print()
    
    results = evaluate_test_set()
    
    print(f"\nâœ… è¯„ä¼°å®Œæˆï¼")
    print(f"æµ‹è¯•å‡†ç¡®ç‡: {results['accuracy']*100:.2f}%")